---
layout: post
title: 矩阵求导基础
tags: 数理基础 矩阵论
math: true
toc: true
date: 2023-6-18 21:56 +0800
---

算是忙里偷闲，学一点无用之用。其实很早就想学一下矩阵求导这东西，但是总是无所事事地忙忙碌碌。难得现在有空那就好好学点有用的东西。

# 0，一点有用的小东西

在正式开始之前，先分享记录一下刚刚学会的一个小技巧：查看网页上面公式的tex代码。

和以前学爬虫的时候一样，方法很简单，就是开发者工具。Ctrl+Shift+C选中需要的元素，然后在右侧开发者工具中找到这个，复制粘贴就可以了。

![image-20230618202842403](D:\pypro\xiejingcheng.github.io\xiejingcheng.github.io\_posts\img\image-20230618202842403.png)

# 1，矩阵求导的本质

最开始接触矩阵求导，应该还是大一的时候，最开接触神经网络的时候，那时候看着哪些五花八门乱七八糟的公式。说起来惭愧，接触的挺早的，但是那时候都只是浅尝辄止，没有认真去学。直到现在才肯静下心来，认真去看看。

其实，更加高阶的矩阵求导知识，似乎要到矩阵论里面，我暂时还只是开个头，等大四了再好好充实自己。

最开始，我们可以给出一个简单的例子和结论，后面再继续探究。

## 1.1，矩阵函数的表示

求导的一个前提就是有一个函数，所以我们先定义一个函数的表达方式。


$$
function(input)
$$


这里定义的很简单，function就是函数，input就是输入。

下面我们要分别讨论输入和输出分别是标量、向量和矩阵的情况。实际上张量用得比较少，但是你可以从前面的继续推理出来。

我们先对$$function(input)$$做一个粗略的表示定义

当 $$function$$ 是一个标量时，我们称之为**实标量函数。**用**细体**小写字母$$f$$表示。

当 $$function$$ 是一个向量时，我们称之为**实向量函数**。用**粗体**小写字母字母$$\pmb{f}$$表示。

当 $$function$$ 是一个矩阵时，我们称之为**实矩阵函数**。用粗体大写字母$$\pmb{F}$$表示。

同样的，当$$input$$为标量、向量和矩阵时候，我们称之为标量变元、向量变元和矩阵变元，分别用$$x$$、$$\pmb{x}$$和$$\pmb{X}$$表示。

下面我举出一个矩阵变元的实矩阵函数的表达，标量变元和向量变元可以看作是他的特化。


$$
\begin{align*} \pmb{F}_{3\times2}(\pmb{X})&= \left[ \matrix{ f_{11}(\pmb{X}) & f_{12}(\pmb{X})\\ f_{21}(\pmb{X}) & f_{22}(\pmb{X})\\ f_{31}(\pmb{X}) & f_{32}(\pmb{X})\\ } \right]\\\\ &= \left[  \matrix{ x_{11}+x_{12}+x_{21}+x_{22}+x_{31}+x_{32} & 2x_{11}+x_{12}+x_{21}+x_{22}+x_{31}+x_{32}\\ 3x_{11}+x_{12}+x_{21}+x_{22}+x_{31}+x_{32} & 4x_{11}+x_{12}+x_{21}+x_{22}+x_{31}+x_{32}\\ 5x_{11}+x_{12}+x_{21}+x_{22}+x_{31}+x_{32} & 6x_{11}+x_{12}+x_{21}+x_{22}+x_{31}+x_{32} } \right] \end{align*} \\\\
$$


当我们的函数，为向量或者标量的时候，我们可以将$$\pmb{F}_{3\times2}(X)$$改成$$\pmb{F}_{3\times1}(X)$$甚至是$$\pmb{F}_{1\times1}(X)$$，而第一行中右边的矩阵则改成对应的形式。同时变元的改变，只是意味着，第一行右边里面的**实标量函数**所拥有的变量数量发生了改变。

到这里，我们已经很好地认识到了矩阵函数的表达形式，那么下一步，就是基础的求导了。

## 1.2，偏导和矩阵求导

在高等数学里面，我们学过多元函数的求偏导，我们可以用这个求偏导得到他的梯度，就像下面这个函数。


$$
f(x_1,x_2,x_3)=x_1^2+x_1x_2+x_2x_3 
$$


然后我们可以很简单的求出它的偏导：


$$
\left\{ \begin{align*} \frac{\partial f}{\partial x_1} & = 2x_1+x_2 \\\\ \frac{\partial f}{\partial x_2} & = x_1+x_3 \\\\ \frac{\partial f}{\partial x_3} & = x_2 \end{align*} \right. \\\\
$$


然后我们把它的三个偏导，按照顺序组成向量的形式，就可以得到它的梯度。其实按照前一小节的定义，这个函数可以看成一个向量变元的实标量函数。而我们通过上面高等数学中的写法，转化成矩阵的表达方式，那我们就得到了向量变元的实标量函数的梯度求法。


$$
\nabla_{\pmb{x}}f(\pmb{x})= \frac{\partial f(\pmb{x})}{\partial \pmb{x}}=  \left[  \frac{\partial f}{\partial x_1},  \frac{\partial f}{\partial x_2},  \cdots, \frac{\partial f}{\partial x_n}  \right]^T \\\\  
$$


那么在这里，我们就可以得到**矩阵求导的本质**，简单来说，所以，如果$$function$$中有$$m$$个$$f$$ ，变元中有$$n$$个元素，那么，每个$$f$$对变元中的每个元素逐个求偏导后，我们就会产生$$m\times n$$个结果。

## 1.3，求导结果的布局

上面那个只是一个基础的结论，他只适用于$$function$$和$$input$$都是向量，准确说是列向量的情况。更加复杂的情况我们需要进一步讨论。



